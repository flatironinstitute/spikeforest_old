#!/usr/bin/env python

import os
import sys
import argparse
import time
import mlprocessors as mlpr
from cairio import client as ca

# This can be important for some of the jobs in certain situations
os.environ['DISPLAY']=''

def main():
  parser = argparse.ArgumentParser(description = 'Listen for batches as a compute resource')
  parser.add_argument('compute_resource_name',help='Name of the compute resource')
  parser.add_argument('--collection',help='Name of collection (e.g., spikeforest)',required=False,default=None)
  parser.add_argument('--share_id',help='Name of share id',required=False, default=None)
  parser.add_argument('--srun_opts',help='Options for slurm\'s srun',required=False,default=None)
  parser.add_argument('--parallel',help='Number of jobs to run in parallel (should not be run in combination with srun_opts)',required=False,default=None)
  parser.add_argument('--allow_uncontainerized',help='Allow jobs to run outside of containers (potentially dangerous)',action='store_true')

  args = parser.parse_args()

  print('compute resource name: {}'.format(args.compute_resource_name))
  print('collection = {}'.format(args.collection))
  print('share_id = {}'.format(args.share_id))
  print('srun opts = {}'.format(args.srun_opts))
  print('num parallel = {}'.format(args.parallel))
  print('allow uncontainerized = {}'.format(args.allow_uncontainerized))

  ca.login()
  server=mlpr.ComputeResourceServer(
      resource_name=args.compute_resource_name,
      collection=args.collection,
      share_id=args.share_id#,
      #allow_uncontainerized=args.allow_uncontainerized
  )
  if args.srun_opts is not None:
    server.setSrunOptsString(args.srun_opts)
  if args.parallel is not None:
    server.setNumParallel(int(args.parallel))
  server.start()

if __name__== "__main__":
  main()
  
